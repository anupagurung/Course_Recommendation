# -*- coding: utf-8 -*-
"""Copy of EDA on Online Course Enrollment Data .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kyOviJXnvL0hAxSH7E2dtcRkvscKPRph
"""

!pip install seaborn==0.11.1
!pip install wordcloud==1.8.1

from google.colab import drive
drive.mount('/content/drive')

!pip install --upgrade matplotlib seaborn

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator

# %matplotlib inline

# Point to the datasets stored on the cloud
course_genre_url = "https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-ML321EN-SkillsNetwork/labs/datasets/course_genre.csv"
ratings_url = "https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-ML321EN-SkillsNetwork/labs/datasets/ratings.csv"

course_df = pd.read_csv(course_genre_url)
ratings_df = pd.read_csv(ratings_url)

course_df.columns

course_df.shape[0]
course_df.head()

course_df.dtypes

course_df.iloc[1, ]

titles = " ".join(title for title in course_df['TITLE'].astype(str))

titles

# English Stopwords
stopwords = set(STOPWORDS)
stopwords.update(["getting started", "using", "enabling", "template", "university", "end", "introduction", "basic"])

from wordcloud import STOPWORDS

# English Stopwords
stopwords = set(STOPWORDS)

# Adding custom stopwords
stopwords.update(["getting started", "using", "enabling", "template", "university", "end", "introduction", "basic"])
wordcloud = WordCloud(stopwords=stopwords, background_color="black", width=400, height=300)

wordcloud.generate(titles)

plt.axis("off")
plt.figure(figsize=(40,20))
plt.tight_layout(pad=0)
plt.imshow(wordcloud, interpolation='bilinear')
plt.show()

from sklearn.feature_extraction.text import TfidfVectorizer
from collections import Counter

# Tokenize the titles and remove stopwords
tokens = [word for word in titles.split() if word.lower() not in stopwords]

# Count word frequencies
word_freq = Counter(tokens)

# Display the most common words
print("Most Common Words (Top 10):")
most_common_words = word_freq.most_common(10)
print(most_common_words)

# Convert course titles to a list
course_titles = course_df['TITLE'].tolist()

# Apply TF-IDF
tfidf_vectorizer = TfidfVectorizer(stop_words=list(stopwords)) # Convert stopwords set to a list
tfidf_matrix = tfidf_vectorizer.fit_transform(course_titles)

# Get feature names (words)
feature_names = tfidf_vectorizer.get_feature_names_out()

# Get the TF-IDF score for each word
tfidf_scores = zip(feature_names, tfidf_matrix.sum(axis=0).A1)
tfidf_scores = sorted(tfidf_scores, key=lambda x: x[1], reverse=True)

# Display the top 10 words by TF-IDF score
print("\nTop 10 Words by TF-IDF Score:")
for word, score in tfidf_scores[:10]:
    print(f"{word}: {score:.4f}")

#Analyze Course Genres
#Find all courses with genre MachineLearning == 1
course_ml_df = course_df[course_df['MachineLearning'] == 1]
course_ml_df

#Find all courses with genres MachineLearning == 1 and BigData == 1
course_ml_bd_df = course_df.loc[(course_df['MachineLearning'] == 1) & (course_df['BigData'] == 1)]
course_ml_bd_df

genres = course_df.columns[2:]
genres

course_df.sum()

x = pd.DataFrame(course_df.sum()).iloc[2:, : ].reset_index().rename(columns={'index': 'Skills', 0: 'count'}).sort_values(by='count', ascending=False)
x

sns.barplot(data=x, x="Skills", y="count")
plt.xticks(rotation=90)
plt.show()

#Analyze Course Enrollments
# look at the course enrollments dataset.
ratings_df.head()

ratings_df['rating'].unique()

ratings_df['rating'].describe()

#see how many ratings/enrollment we have in the dataset:
ratings_df.shape[0]

# Apply Pandas' groupby() and size() method on the user column to aggregate the rating count for each user, then report the total number of users after aggregation.
user_count_df = ratings_df.groupby('user').size()
user_count_df

user_count_df.describe()

#Plot the histogram of user rating counts.
user_count_df.hist()

#Finding the Top-20 Most Popular Courses
item_count_df = ratings_df.groupby('item').size()
item_count_df

item_count_df.sort_values()[-20:]

#Using Pandas merge() method to join the course_df (contains the course title column).
course_count_df = pd.DataFrame(item_count_df.sort_values()[-20:]).reset_index().rename(columns={'item': 'COURSE_ID', 0: 'count'})
course_count_df

pd.merge(course_count_df, course_df[['COURSE_ID','TITLE']],on='COURSE_ID', how='left')

# Get the total course enrollments again
total = ratings_df.shape[0]
total

top = course_count_df['count'].sum()

print(f"Percentage of the top course enrollments {round((top * 100)/total, 2)}%")